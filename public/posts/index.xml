<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Prem Seetharaman</title>
    <link>https://pseeth.github.io/posts/</link>
    <description>Recent content in Posts on Prem Seetharaman</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2023, Prem Seetharaman</copyright>
    <lastBuildDate>Sun, 01 Sep 2019 07:00:00 +0000</lastBuildDate>
    <atom:link href="https://pseeth.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Bootstrapping the learning process for computer audition</title>
      <link>https://pseeth.github.io/posts/bootstrapping-the-learning-process-for-computer-audition/</link>
      <pubDate>Sun, 01 Sep 2019 07:00:00 +0000</pubDate>
      <guid>https://pseeth.github.io/posts/bootstrapping-the-learning-process-for-computer-audition/</guid>
      <description>I defended my thesis in September 2019! It was about learning to segment complex auditory scenes into constituent sources without access to ground truth training data. I developed a method for bootstrapping a deep learning model via primitives - hard-wired auditory grouping principles that have been observed in the mammalian auditory cortex. The primitive estimates were then used in concert with a confidence measure to train a deep audio source separation model.</description>
    </item>
    <item>
      <title>Bootstrapping speech separation from unsupervised spatial separation</title>
      <link>https://pseeth.github.io/posts/bootstrapping-speech-separation-from-unsupervised-spatial-separation/</link>
      <pubDate>Sun, 10 Feb 2019 08:00:00 +0000</pubDate>
      <guid>https://pseeth.github.io/posts/bootstrapping-speech-separation-from-unsupervised-spatial-separation/</guid>
      <description>Separating an audio scene into isolated sources is a fundamental problem in computer audition, analogous to image segmentation in visual scene analysis. Source separation systems based on deep learning are currently the most successful approaches for solving the underdetermined separation problem, where there are more sources than channels. Traditionally, such systems are trained on sound mixtures where the ground truth decomposition is already known. Since most real-world recordings do not have such a decomposition available, this limits the range of mixtures one can train on, and the range of mixtures the learned models may successfully separate.</description>
    </item>
  </channel>
</rss>
